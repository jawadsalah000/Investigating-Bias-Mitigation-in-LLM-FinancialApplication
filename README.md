# Investigating Bias Mitigation in Large Language Models for Financial Decision-Making

This repository contains all code, datasets, and results accompanying the MSc dissertation:

> **â€œInvestigating Bias Mitigation in Large Language Models for Classification Tasks in Financial Decision-Makingâ€**
> Jawad Salah, MSc Venture Capital & Private Equity with FinTech, University College London (2025)
> Supervised by Prof. Ramin Okhrati (UCL) & Andrea Bassani (NatWest Group PLC).

---

## ğŸ“‘ Overview

The dissertation evaluates whether latest-generation Large Language Models (LLMs) exhibit **social biases** in financial decision making tasks, before investigation various methods to mitigate that bias. Using **mortgage underwriting** as a testbed, experiments were run on GPT-5, GPT-5 Nano, and Gemini 2.5 Flash Lite with multiple **prompt-engineering strategies**.

Two fairness metrics were used:

* **Demographic Approval Parity (DAP)** â€“ group-level disparity.
* **Absolute Approval Bias (AAB)** â€“ model sensitivity to explicit race labels (introduced in this study).

The project demonstrates that **Chain-of-Thought (CoT) prompting** was the most effective mitigation method, though effectiveness was model-dependent and sometimes came at a computational cost.

---

## ğŸ“‚ Repository Structure

```
Repository Root
â”‚
â”œâ”€â”€ Dataset
â”‚   â”œâ”€â”€ Input
â”‚   â”‚   â”œâ”€â”€ Boot-Strapped Synthetic Dataset.xlsx
â”‚   â”‚   â”œâ”€â”€ Counterfactual Synthetic Dataset 1.xlsx
â”‚   â”‚   â”œâ”€â”€ Counterfactual Synthetic Dataset 2.xlsx
â”‚   â”‚   â””â”€â”€ Pre-processed Dataset.xls
â”‚   â”‚
â”‚   â””â”€â”€ Results
â”‚       â”œâ”€â”€ Bias Identification and Mitigation Tests
â”‚       â”‚   â”œâ”€â”€ GPT-5 Nano
â”‚       â”‚   â”‚   â””â”€â”€ Reasoning vs Bias Experiment
â”‚       â”‚   â”œâ”€â”€ GPT-5 / Minimal Reasoning
â”‚       â”‚   â””â”€â”€ Gemini 2.5 Flash Lite
â”‚       â”‚
â”‚       â”œâ”€â”€ Categorical vs. Continuous Experiment
â”‚       â”œâ”€â”€ Proxies Experiment
â”‚       â””â”€â”€ Temperature Study
â”‚
â”œâ”€â”€ Notebooks
â”‚   â”œâ”€â”€ 1) Data Pre-Processing and Exploration.ipynb
â”‚   â”œâ”€â”€ 2) Counterfactual Input Testing.ipynb
â”‚   â”œâ”€â”€ 3) Bias Identification Experiment.ipynb
â”‚   â”œâ”€â”€ 4) Zero Shot Prompt Engineering for Bias Mitigation.ipynb
â”‚   â”œâ”€â”€ 5.1) GPT 5 Results and Analysis.ipynb
â”‚   â”œâ”€â”€ 5.2) GPT 5 Nano Results and Analysis.ipynb
â”‚   â”œâ”€â”€ 5.3) Gemini Results and Analysis.ipynb
â”‚   â””â”€â”€ 6) Reasoning Level vs Bias Test (Nano).ipynb
â”‚
â”œâ”€â”€ scripts
â”‚   â””â”€â”€ prompts.py   # All baseline and engineered prompts
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ How to Use

1. Clone the repo:

   ```bash
   git clone https://github.com/jawadsalah000/Investigating-Bias-Mitigation-in-LLM-FinancialApplication.git
   cd Investigating-Bias-Mitigation-in-LLM-FinancialApplication
   ```
2. Install dependencies (Python 3.10+ recommended):

   ```bash
   pip install -r requirements.txt
   ```
3. Explore the Jupyter Notebooks in the `Notebooks/` folder for step-by-step replication of experiments.
4. Use `scripts/prompts.py` to access the exact prompts used (baseline, reasoning, CoT, fairness phrasing).

---

## ğŸ“Š Key Contributions

* Introduced **Absolute Approval Bias (AAB)** metric to detect race-sensitivity bias.
* Ran **systematic audits on the GPT-5 series and Gemini 2.5**.
* Found **CoT prompting most effective** in reducing disparities across models using group-level bias metrics.
* Released full datasets, notebooks, and result files for **reproducibility and transparency**.

---

## ğŸ“– Citation

If you use this work, please cite:

```
Salah, J. (2025). Investigating Bias Mitigation in Large Language Models for Classification Tasks 
in Financial Decision-Making. MSc Dissertation, University College London.
```

---

Do you want me to also add a **â€œResults at a Glanceâ€ section** in the README with your key tables/figures (like GPT-5 vs Nano vs Gemini baseline bias outcomes) so people see findings instantly?
